Computer10 will use iterative deepening. It will use ordering only at the first level. It will get the ordering from the last iteration

Computer11 might use ordering at the first two levels from previous iterations. It may be possible to use all levels of previous iterations, maybe with a hash table.

Can processing become faster if r and g are replaced by something more binary?

Make the computer able to play versus itself, repeatedly. That is, a Dom program should ask the user who the players should be, and their time limits and characteristics.

Is it a waste to use e to the power?

Change the static evaluator such that it considers not only relative moves, but also centrality, height of towers, etc. To do this, have Dom strategies evolve against each other.

If the game becomes repetitive or there are no more captures, maybe the computer should adjust its strategy. Maybe try to combine towers to get reserves.
---------------------------------------------------
OK. What do I need to do? I should change the static evaluator because it's the program's greatest weakness.

I need a way to have two programs play against each other so that I can compare them. 

I should try MCTS, which I now sort of understand. See the Google
paper and the Wikipedia page. This will be a more major revision.


And I can try making the static evaluator into a neural network, which will
be an even more major change.
---------------------------------

OK, so I have a minimax and an MCTS. Is ordering at all useful to make
minimax faster? Using the optimize attribute of Board, I've made MCTS
20 times faster, and I bet minimax can become faster once I implement
that. MCTS has performed best so far when its curiosity is 0, not 0.1,
0.5, 1, or 2. It seems I need MCTS to have 20 seconds to beat 2-ply
(plays in a second), and 120 seconds to beat 3-ply (plays in roughly
10 seconds). But I haven't tested MCTS against 4-ply because 4-ply can
takes at least 10 minutes per move. I need to know what the best
curiosity value is. Then I need to start working on a static evaluator
function. Just counting red and green pieces (score4) is not a good
plan, as red can win even though there are lots of captured green
pieces on the board. After talking with Thomas, I'm considering adding
a function that counts the number of towers controlled by each side,
and a function that counts just reserve pieces. And then I would have
to do the weights on those scoring systems.

Should I make the programs print their predictions of the most likely moves?
        
-----------------------------------
With score5, it seems that minimax is a significant bit better than
MCTS, no matter how I try to improve MCTS. I wonder if there is a
way to make MCTS faster --- maybe avoid storing all the boards
for each node, but instead use fewer boards? But that would be
a drastic change, and so would changing the static evaluator.
            
---------------------------------------------------
OK. So Thomas can beat minimax 4-ply. What can I try?

1. Make the two additional static evaluators that I mentioned
earlier and play with the weights until minimax 4-ply improves.
This is the easiest step.

2. I can make a new scorer that plays the best 1-ply move
for, say, 10 plys and then averages out the static evaluation
scores of those 10 plys. (With win/loss counting extra to make
a full 10.) This scorer would take more time.

3. Is 5-ply possible? Is it possible on the iMac?

4. Make compare.py able to take initial moves as input.
And can the computers ask the players for their settings?
Otherwise compare.py will get bulky.

5. The computer needs a better "killer instinct" at the end of
games. Maybe I should run both MCTS and minimax, and pick the
one that has the more optimistic score. (More pessimistic,
if it's losing?)

6. I want to understand why the theoretical justification for
exploration isn't working for MCTS in Domination. Is Google's magic
formula actually magic that will work for me?

------------------------------------------------------

Maybe I should modify MCTS so at each choice it picks the best-scoring
move if that move has less than 90% (say) of picks so far. But it should
always choose untouched nodes first.

And MCTS should get to ignore bad reserve placements like minimax does.


Maybe MCTS should focus on the 3 (say) best moves? Hydra tried to look at
all 50 and failed, but surely just the 3 best moves would give it a little
curiosity without sacrificing thinking time on each choice.


The easiest thing to do right now is create a scoring system that counts
5-towers. Then average that with the classic scoring, and see whether
minimax 4-ply gets better.

---------------------------------------------------
Written January-ish 2020, but typed up 14 March 2020
Thus I've made some clarifying comments.

Different curiosities at different moves? Or different proportions
[for MCTS---the computer must spend 50% of the time on the best move
so far, 25% on the 2nd-best, etc.].

The scoring system that plays a few ahead might be good. But really
this is Hydra and why did Hydra do so badly? [Because it needed more
time] Does it just need more time? [Yes] 1000s? [Yeah, try that] Can
120s MCTS beat 20s MCTS? What is MCTS even doing with the graph?
i.e. Is it just following one line of thought 30 moves ahead, an utter
waste of time? I just don't understand the magic formula, so I'm
tempted to change to the proportional system. "Magic" is the key word
here. And is MCTS maintaining lots of boards that it doesn't need?
Does a non-leaf node even need a Board anymore? To be fair, it might
be even better to have just one board, but that might be
complicated---I would need a faster move() function, one that doesn't
bother to check.


Of course, 5-ply could beat 4-ply, but I don't want to go there quite yet.
If I'm after speed, I can probably optimize the board or use Cython. But I want cleverness too. Yeah, Deep Blue used speed to win. But I'm living in the age of AlphaZero. So I need a better static evaluator function, or even a neural network.

Or should a leaf node only get a Board when it is expanded? After all,
there are probably a lot more leaf nodes that other nodes.

Or maybe MCTS should spend 1/2 its time on the best node, 1/4 on the
next node, and so on---but all nodes at least 1 [playout] 1st, and
[then] 1st we fill up the 1/2, then the 1/4, ....

Change how much score3 values reserve pieces? Yes. 1/2 and 2 times as
much.  And do the 90% proportional system.

-----------------------------
14 March 2020

I need to write up the games from January, but I recall that 1000
second Hydra did better than 4-ply. To some extent, we can think of
MCTS as a static evaluator, which in Hydra is called by 1-ply.

My attempts to change the actual static evaluator did not work out.
Since Hydra beat 4-ply, we know MCTS with 20ish seconds (I should look
at the data to see) is a better static evaluator than 3-ply is. And
since Hydra beat 1000 second minimax (4 and 5-ply), it might be a better
static evaluator than 4-ply.

I'm thinking of running a lot of games of 4-ply vs 4-ply, which will
have lots of good positions but not take as long as 1000 second
Hydra. I'll store each Board position with the 4-ply evalation and
then also the 20ish second MCTS evaluation of what the Board is
worth. I'll have to run quite a lot of games for that, so I don't
think I'll collect most of the data until I'm back in Cambridge. But I
can write the data-collection program soon.

Then later I can train a neural network that imitates 4-ply evaluation
and one that imitates 20ish second MCTS. Since the network should take
1 second or so to evaluate, I can then run a 3-ply or so minimax,
which hopefully is like a 7-ply minimax or Hydra with 3-ply,
respectively.

I've improved how the computer searches for moves, in that 1000 second Hydra beats 1000 second minimax, and I could have had minimax that strong in 9th grade if I was willing to wait a long time. But when the computer has to actually evaluate a board, it uses the same division method as in 9th grade. (Was it 9th grade? Maybe 10th?) And adjusting that has not helped much, so I might as well throw a neural network at it. Worst case, I'll have a lot of data, so I can manually guess and check heuristics that have a high correlation with the 4-ply/MCTS 20ish seconds result.
