Computer10 will use iterative deepening. It will use ordering only at the first level. It will get the ordering from the last iteration

Computer11 might use ordering at the first two levels from previous iterations. It may be possible to use all levels of previous iterations, maybe with a hash table.

Can processing become faster if r and g are replaced by something more binary?

Make the computer able to play versus itself, repeatedly. That is, a Dom program should ask the user who the players should be, and their time limits and characteristics.

Is it a waste to use e to the power?

Change the static evaluator such that it considers not only relative moves, but also centrality, height of towers, etc. To do this, have Dom strategies evolve against each other.

If the game becomes repetitive or there are no more captures, maybe the computer should adjust its strategy. Maybe try to combine towers to get reserves.
---------------------------------------------------
OK. What do I need to do? I should change the static evaluator because it's the program's greatest weakness.

I need a way to have two programs play against each other so that I can compare them. 

I should try MCTS, which I now sort of understand. See the Google
paper and the Wikipedia page. This will be a more major revision.


And I can try making the static evaluator into a neural network, which will
be an even more major change.
---------------------------------

OK, so I have a minimax and an MCTS. Is ordering at all useful to make
minimax faster? Using the optimize attribute of Board, I've made MCTS
20 times faster, and I bet minimax can become faster once I implement
that. MCTS has performed best so far when its curiosity is 0, not 0.1,
0.5, 1, or 2. It seems I need MCTS to have 20 seconds to beat 2-ply
(plays in a second), and 120 seconds to beat 3-ply (plays in roughly
10 seconds). But I haven't tested MCTS against 4-ply because 4-ply can
takes at least 10 minutes per move. I need to know what the best
curiosity value is. Then I need to start working on a static evaluator
function. Just counting red and green pieces (score4) is not a good
plan, as red can win even though there are lots of captured green
pieces on the board. After talking with Thomas, I'm considering adding
a function that counts the number of towers controlled by each side,
and a function that counts just reserve pieces. And then I would have
to do the weights on those scoring systems.

Should I make the programs print their predictions of the most likely moves?
        
-----------------------------------
With score5, it seems that minimax is a significant bit better than
MCTS, no matter how I try to improve MCTS. I wonder if there is a
way to make MCTS faster --- maybe avoid storing all the boards
for each node, but instead use fewer boards? But that would be
a drastic change, and so would changing the static evaluator.
            
---------------------------------------------------
OK. So Thomas can beat minimax 4-ply. What can I try?

1. Make the two additional static evaluators that I mentioned
earlier and play with the weights until minimax 4-ply improves.
This is the easiest step.

2. I can make a new scorer that plays the best 1-ply move
for, say, 10 plys and then averages out the static evaluation
scores of those 10 plys. (With win/loss counting extra to make
a full 10.) This scorer would take more time.

3. Is 5-ply possible? Is it possible on the iMac?

4. Make compare.py able to take initial moves as input.
And can the computers ask the players for their settings?
Otherwise compare.py will get bulky.

5. The computer needs a better "killer instinct" at the end of
games. Maybe I should run both MCTS and minimax, and pick the
one that has the more optimistic score. (More pessimistic,
if it's losing?)

6. I want to understand why the theoretical justification for
exploration isn't working for MCTS in Domination. Is Google's magic
formula actually magic that will work for me?

